{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10761287\n"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "#print(\"Character length...\",char_len)\n",
    "file = unidecode.unidecode(open(\"corpus.txt\").read())\n",
    "file_len = len(file)\n",
    "print(len_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ty so far is as usual for a typical Thursday.\n",
      "Would you like to do some more exercises with me?\n",
      "What would you like to do next?\n",
      "\"We can talk, relax with mindfulness, or do something physical.\"\n",
      "\"Hi! I'm\n"
     ]
    }
   ],
   "source": [
    "chunk_len = 200\n",
    "\n",
    "def random_chunk():\n",
    "    start_index = random.randint(0, file_len - chunk_len)\n",
    "    end_index = start_index + chunk_len + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 10\n",
      " 11\n",
      " 12\n",
      " 39\n",
      " 40\n",
      " 41\n",
      "[torch.LongTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Turn string into list of longs\n",
    "def char_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for c in range(len(string)):\n",
    "        tensor[c] = all_characters.index(string[c])\n",
    "    return Variable(tensor)\n",
    "\n",
    "print(char_tensor('abcDEF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_training_set():    \n",
    "    chunk = createChunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, hidden = decoder(prime_input[p], hidden)\n",
    "    inp = prime_input[-1]\n",
    "    \n",
    "    for p in range(predict_len):\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "\n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output, target[c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2m 38s (100 2%) 2.0653]\n",
      "Whatd you #BRY.\n",
      "For beelit.\"\n",
      "Rexpreath whese whind you carve to in you feeling or #BRY.gi\n",
      "Feell where  \n",
      "\n",
      "[5m 16s (200 4%) 0.9017]\n",
      "Wheren usee for -> you  and wat makas bay Helk\n",
      "Ok\n",
      "\"Ye you're for nam the for frit the for  -> Say feel \n",
      "\n",
      "[8m 4s (300 6%) 1.3663]\n",
      "What gratitude and how se you're ned or help unde st or ing not you bak and them por ind feeling arst. \n",
      "\n",
      "[10m 54s (400 8%) 2.0323]\n",
      "Whalk activations see would you thanks that though the theful to thing you to what any say #CBT you ta \n",
      "\n",
      "[13m 11s (500 10%) 1.6926]\n",
      "Wh though that active.\"\n",
      "\"Tis alalongh its is is inse from to fiend, help you day. Aned to to the food  \n",
      "\n",
      "[17m 58s (600 12%) 1.4138]\n",
      "Whenegatich and will usee to sees or wise you like you sarnt alaart an with a sidee your hacke of to w \n",
      "\n",
      "[20m 40s (700 14%) 1.0461]\n",
      "What's your name?\n",
      "Here feeling bad and can low?\n",
      "I can a ram You are are from lise realillog, as better \n",
      "\n",
      "[23m 23s (800 16%) 1.6447]\n",
      "What you reathe feel. And wis thoughte to the far. Whear stress of everyday life. When you sa you thin \n",
      "\n",
      "[26m 16s (900 18%) 1.4308]\n",
      "What's bechag (o   how does or #WOHworto helping you are feeling allpays when you 'refeling \"\"\"\"\"\"\"\"\"\" \n",
      "\n",
      "[29m 9s (1000 20%) 1.3260]\n",
      "What is -> CBT and werks, real which would becisse overgy, what which works, or reporlied dore -> Say  \n",
      "\n",
      "[31m 39s (1100 22%) 2.7500]\n",
      "What day....l.\n",
      "How I can I'm here to help you want ming...\n",
      "How do out your ance?preted angan any belle \n",
      "\n",
      "[33m 37s (1200 24%) 1.6927]\n",
      "When you're happentoding inte.\"\n",
      "Ready with more usuto do you have nee.\"\n",
      "You'lnes?\n",
      "'think it to this it \n",
      "\n",
      "[35m 45s (1300 26%) 0.3826]\n",
      "What would help por achand action 'rele says and calm me and would with think a bady.\n",
      "https://s3-ap-so \n",
      "\n",
      "[37m 54s (1400 28%) 0.8890]\n",
      "What wor do or stress -> Say #MOVE, #REATHE, or #RELAX.\n",
      "https://s3-ap-southeast-1.amazonaws.com/it+thi \n",
      "\n",
      "[40m 1s (1500 30%) 0.6921]\n",
      "Wholltases. These it ill leased you deas.\"\n",
      "Done\n",
      "https://s3-ap-southeast-1.amazonaws.com/bot-content/gi \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 500\n",
    "n_layers = 1\n",
    "lr = 0.005\n",
    "\n",
    "decoder = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(*random_training_set())       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
    "        print(evaluate('Wh', 100), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
